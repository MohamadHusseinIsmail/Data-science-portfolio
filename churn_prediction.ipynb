{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPz0YeC58JrCDoriVjtXJZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamadHusseinIsmail/Data-science-portfolio/blob/main/churn_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2br7yw3j5AH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "churn_data = pd.read_csv('/content/Churn_Modelling.csv')"
      ],
      "metadata": {
        "id": "DNfcprNHkU86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Drop unnecessary columns\n",
        "churn_data_cleaned = churn_data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
        "\n",
        "# Encode categorical features\n",
        "label_encoder = LabelEncoder()\n",
        "churn_data_cleaned['Gender'] = label_encoder.fit_transform(churn_data_cleaned['Gender'])\n",
        "churn_data_cleaned = pd.get_dummies(churn_data_cleaned, columns=['Geography'], drop_first=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = churn_data_cleaned.drop('Exited', axis=1)\n",
        "y = churn_data_cleaned['Exited']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "gmlk2nwmkokP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Initialize models\n",
        "logistic_model = LogisticRegression(random_state=42)\n",
        "random_forest_model = RandomForestClassifier(random_state=42)\n",
        "gradient_boosting_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "logistic_model.fit(X_train, y_train)\n",
        "logistic_preds = logistic_model.predict(X_test)\n",
        "\n",
        "# Random Forest\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "rf_preds = random_forest_model.predict(X_test)\n",
        "\n",
        "# Gradient Boosting\n",
        "gradient_boosting_model.fit(X_train, y_train)\n",
        "gb_preds = gradient_boosting_model.predict(X_test)"
      ],
      "metadata": {
        "id": "emih4ilskvYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy and classification reports for each model\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logistic_preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, logistic_preds))\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, rf_preds))\n",
        "\n",
        "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, gb_preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, gb_preds))\n"
      ],
      "metadata": {
        "id": "rjrgSYgfk1H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set visualization style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Churn Distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='Exited', data=churn_data_cleaned, palette='viridis')\n",
        "plt.title(\"Churn Distribution\")\n",
        "plt.xlabel(\"Churn (Exited)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks([0, 1], ['Retained', 'Churned'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lUCyLltSm812"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Random Forest model to extract feature importance\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest_model = RandomForestClassifier(random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Extract and plot feature importances\n",
        "feature_importances = pd.Series(random_forest_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=feature_importances, y=feature_importances.index, palette='viridis')\n",
        "plt.title(\"Feature Importance - Random Forest\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "YHEoOMh6nB4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Churn by Age\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=churn_data_cleaned, x='Age', hue='Exited', multiple=\"stack\", palette=\"viridis\", bins=30)\n",
        "plt.title(\"Churn by Age\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TCy1MWeTnLRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Churn by Balance\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=churn_data_cleaned, x='Balance', hue='Exited', multiple=\"stack\", palette=\"viridis\", bins=30)\n",
        "plt.title(\"Churn by Balance\")\n",
        "plt.xlabel(\"Balance\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "vvJFh7-2nRDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "BLbvJHb9oYX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LoyaltyScore feature as an example\n",
        "churn_data_cleaned['LoyaltyScore'] = churn_data_cleaned['Tenure'] * churn_data_cleaned['IsActiveMember']\n"
      ],
      "metadata": {
        "id": "IBsrrI_OoaPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(churn_data_cleaned.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Feature Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kHZROv2Eodpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize and train the XGBoost model\n",
        "xgb_model = XGBClassifier(random_state=42)\n",
        "xgb_model.fit(X_train_sm, y_train_sm)\n",
        "\n",
        "# Make predictions\n",
        "xgb_preds = xgb_model.predict(X_test)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20],\n",
        "    'min_samples_split': [5, 10]\n",
        "}\n",
        "\n",
        "# Initialize model and GridSearch\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train_sm, y_train_sm)\n",
        "\n",
        "# Best parameters and accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "id": "RrQeuh5Coi9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "\n",
        "# Predict probabilities for ROC-AUC\n",
        "rf_probs = grid_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, rf_probs)\n",
        "\n",
        "# Plot ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, rf_probs)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color=\"darkorange\", label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC-AUC Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IFSBlBlypWIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "churn_data_cleaned['Cluster'] = kmeans.fit_predict(X)\n",
        "\n",
        "# Plot clusters by age and balance for visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Age', y='Balance', hue='Cluster', data=churn_data_cleaned, palette=\"viridis\")\n",
        "plt.title(\"Customer Segmentation by Age and Balance\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Balance\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tfN4TtWLpdMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define pipeline steps\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Train the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "pipeline_preds = pipeline.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pipeline_preds))\n"
      ],
      "metadata": {
        "id": "ZSeZu8BWwxpU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}