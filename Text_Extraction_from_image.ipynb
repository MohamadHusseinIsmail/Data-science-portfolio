{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP72mKzcRXLjgKQuhacc9d/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamadHusseinIsmail/Data-science-portfolio/blob/main/Text_Extraction_from_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2GeLc3VZKIy"
      },
      "outputs": [],
      "source": [
        "#import requests to install tesseract\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading tesseract-ocr file\n",
        "r = requests.get(\"https://raw.githubusercontent.com/tesseract-ocr/tessdata/4.00/ind.traineddata\", stream = True)\n",
        "\n",
        "# Writing data to file to avoid path isuues\n",
        "with open(\"/usr/share/tesseract-ocr/4.00/tessdata/ind.traineddata\", \"wb\") as file:\n",
        "    for block in r.iter_content(chunk_size = 1024):\n",
        "         if block:\n",
        "             file.write(block)"
      ],
      "metadata": {
        "id": "_mcqKdZxZOx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing libraries required for optical character recognition\n",
        "! apt install tesseract-ocr libtesseract-dev libmagickwand-dev\n",
        "\n",
        "# Importing IPython to clear output which is not important\n",
        "from IPython.display import HTML, clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "g940X8NqZR43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing pytesseract and opencv\n",
        "! pip install pytesseract wand opencv-python\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "PiR0W16rZW8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Import libraries\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pytesseract import Output\n",
        "import re"
      ],
      "metadata": {
        "id": "bNqYH3F2ZeYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading image form url\n",
        "image = Image.open(requests.get('https://i.stack.imgur.com/pbIdS.png', stream=True).raw)\n",
        "image = image.resize((300,150))\n",
        "image.save('sample.png')\n",
        "image"
      ],
      "metadata": {
        "id": "ZLKW0_lhZiD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simply extracting text from image\n",
        "custom_config = r'-l eng --oem 3 --psm 6'\n",
        "text = pytesseract.image_to_string(image,config=custom_config)\n",
        "print(text)"
      ],
      "metadata": {
        "id": "mBdlC7GjZklA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting text from image and removing irrelevant symbols from characters\n",
        "try:\n",
        "  text=pytesseract.image_to_string(image,lang=\"eng\")\n",
        "  characters_to_remove = \"!()@—*“>+-/,'|£#%$&^_~\"\n",
        "  new_string = text\n",
        "  for character in characters_to_remove:\n",
        "    new_string = new_string.replace(character, \"\")\n",
        "  print(new_string)\n",
        "except IOError as e:\n",
        "    print(\"Error (%s).\" % e)"
      ],
      "metadata": {
        "id": "dANIymcfZoq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we will perform opencv operations to get text from complex images\n",
        "image = cv2.imread('sample.png')"
      ],
      "metadata": {
        "id": "nHRpwJgDZsID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get grayscale image\n",
        "def get_grayscale(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "gray = get_grayscale(image)\n",
        "Image.fromarray(gray)"
      ],
      "metadata": {
        "id": "gEY-zFFmZuXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# noise removal\n",
        "def remove_noise(image):\n",
        "    return cv2.medianBlur(image,5)\n",
        "noise = remove_noise(gray)\n",
        "Image.fromarray(gray)"
      ],
      "metadata": {
        "id": "y7Jcx8FxZ10m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#thresholding\n",
        "def thresholding(image):\n",
        "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "thresh = thresholding(gray)\n",
        "Image.fromarray(thresh)"
      ],
      "metadata": {
        "id": "4OopDGFvZ6NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#erosion\n",
        "def erode(image):\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    return cv2.erode(image, kernel, iterations = 1)\n",
        "erode = erode(gray)\n",
        "Image.fromarray(erode)"
      ],
      "metadata": {
        "id": "krTS7jGOZ9Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Morphology\n",
        "def opening(image):\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
        "opening = opening(gray)\n",
        "Image.fromarray(opening)"
      ],
      "metadata": {
        "id": "Rc9lmM_JZ_aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#canny edge detection\n",
        "def canny(image):\n",
        "    return cv2.Canny(image, 100, 200)\n",
        "canny = canny(gray)\n",
        "Image.fromarray(canny)"
      ],
      "metadata": {
        "id": "1t5n4oq8aCwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#skew correction\n",
        "def deskew(image):\n",
        "    coords = np.column_stack(np.where(image > 0))\n",
        "    angle = cv2.minAreaRect(coords)[-1]\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "        angle = -angle\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "    return rotated\n",
        "rotated = deskew(gray)\n",
        "Image.fromarray(rotated)"
      ],
      "metadata": {
        "id": "uZHEu7hWaIG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#template matching\n",
        "def match_template(image, template):\n",
        "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
        "match = match_template(gray, gray)\n",
        "match"
      ],
      "metadata": {
        "id": "6T28UEGvaL5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drawing rectangle around text\n",
        "img = cv2.imread('sample.png')\n",
        "h, w, c = img.shape\n",
        "boxes = pytesseract.image_to_boxes(img)\n",
        "for b in boxes.splitlines():\n",
        "    b = b.split(' ')\n",
        "    img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
        "Image.fromarray(img)"
      ],
      "metadata": {
        "id": "JmR_q99HaOZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drawing pattern on specific pattern or word\n",
        "img = cv2.imread('sample.png')\n",
        "d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
        "keys = list(d.keys())\n",
        "\n",
        "date_pattern = 'artificially'\n",
        "\n",
        "n_boxes = len(d['text'])\n",
        "for i in range(n_boxes):\n",
        "    if int(d['conf'][i]) > 60:\n",
        "    \tif re.match(date_pattern, d['text'][i]):\n",
        "\t        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
        "\t        img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "Image.fromarray(img)"
      ],
      "metadata": {
        "id": "2-AAJHHsaVvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}